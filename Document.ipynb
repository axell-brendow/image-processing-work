{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reconhecimento de padrões por textura em imagens mamográficas\n",
    "Pontificia Universidade Catolica de Minas Gerais\n",
    "\n",
    "Axell Brendow\n",
    "\n",
    "Raiana Pereira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição do problema\n",
    "A  densidade  da  mama  é  comprovadamente  relacionada  com  o  risco  do  desenvolvimento  de  câncer, uma vez que  mulheres com uma maior densidade mamária podem esconder lesões, levando o câncer a  ser  detectado  tardiamente.  A  escala  de  densidade  chamada  BIRADS  foi  desenvolvida  pelo American  College  of  Radiology  e  informa  os  radiologistas  sobre  a  diminuição  da  sensibilidade  do exame  com  o  aumento  da  densidade  da  mama.  BI-RADS  definem  a  densidade  como  sendo  quase inteiramente composta por gordura (densidade I), por tecido fibrobroglandular difuso (densidade II), por tecido denso heterogêneo (III) e por tecido extremamente denso (IV). A mamografia é a principal ferramenta  de  rastreio  do  câncer  e  radiologistas  avaliam  a  densidade  da  mama  com  base  na  análise visual das imagens.\n",
    "\n",
    "Sendo assim, o principal problema é analisar a densidade da mama para detecção ou não do cancêr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivação e objetivos do trabalho\n",
    "O objetivo do trabalho é implementar um aplicativo que leia imagens de exames mamográficos e possibilite o reconhecimento automático da densidade da mama, utilizando técnicas de descrição por textura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição das técnicas implementadas para a solução, principalmente do classificador\n",
    "O classificador escolhido para o trabalho é uma rede neural completamente conectada.\n",
    "\n",
    "Tivemos 71% de acurácia com 2000 épocas de treino, usando 256 neurônios na primeira camada da rede neural e usando a função de ativação [retificadora](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)).\n",
    "\n",
    "A segunda e última camada da rede neural tem 4 neurônios que correspondem às 4 classes BIRADS.\n",
    "\n",
    "O otimizador da rede neural usa o algoritmo de Adam e a métrica extraída é a acurácia.\n",
    "\n",
    "As imagens podem ser descritas por todos os 13 primeiros descritores do artigo \"[Textural Features for Image Classification](https://ieeexplore.ieee.org/document/4309314)\" mais os 7 momentos invariantes de Hu:\n",
    "\n",
    "- Energia\n",
    "- Contraste\n",
    "- Correlação\n",
    "- Variância\n",
    "- Homogeneidade\n",
    "- Soma média\n",
    "- Soma da variância\n",
    "- Soma da entropia\n",
    "- Entropia\n",
    "- Diferença da variância\n",
    "- Diferença da entropia\n",
    "- Medida de informação de correlação 12\n",
    "- Medida de informação de correlação 13\n",
    "- Todos os 7 momentos invariantes de Hu\n",
    "\n",
    "Formato dos dados de treinamento e teste:\n",
    "\n",
    "A rede neural recebe um vetor D (descritores) onde D\\[i\\] contém o arranjo de descritores de uma imagem e um vetor C (classes) onde C\\[i\\] contém a classe esperada para essa imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências das bibliotecas utilizadas e instruções para instalação\n",
    "\n",
    "\n",
    "Lista das bibliotecas ultilizadas:\n",
    "\n",
    "- autopep8==1.5.4\n",
    "- mahotas==1.4.11\n",
    "- matplotlib==3.3.3\n",
    "- numpy==1.19.2\n",
    "- pycodestyle==2.6.0\n",
    "- pydicom==2.0.0\n",
    "- opencv-python==4.4.0.44\n",
    "- Pillow==7.2.0\n",
    "- tensorflow==2.3.1\n",
    "\n",
    "Para instalar as bibliotecas e executar o projeto usamos versões do Python entre 3.6.9 e 3.8.\n",
    "\n",
    "Abra a pasta do projeto no terminal e execute (troque python3 por python no Windows):\n",
    "```\n",
    "python3 -m pip install --upgrade pip\n",
    "python3 -m pip install -r requirements.txt\n",
    "python3 main.py\n",
    "```\n",
    "\n",
    "Esses comandos irão instalar as dependências do projeto e rodar o arquivo principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas  de  tempo  de  execução  para  diversas  imagens,  descritores  e  hiperparâmetros  do classificador\n",
    "\n",
    "Ao treinar o classificador com o conjunto de imagens de teste obteu-se as seguintes métricas:\n",
    "\n",
    "      Execution time (sec)      Accuracy     Sensitivity   Specificity   Num. of neurons     Num. of epochs  \n",
    "     \n",
    "      1,4096086025238           0,55           0,55           0,85             32                100         \n",
    "     5,41321229934692           0,54           0,54           0,85             32                500         \n",
    "     11,3145925998688            0,6            0,6           0,87             32                1000        \n",
    "     23,9920816421509           0,65           0,65           0,88             32                2000        \n",
    "     36,6627986431122           0,58           0,58           0,86             32                3000        \n",
    "     50,3295865058899           0,65           0,65           0,88             32                4000        \n",
    "     58,3313910961151           0,58           0,58           0,86             32                5000        \n",
    "     1,51882433891296           0,61           0,61           0,87             64                100         \n",
    "     5,52890706062317           0,62           0,62           0,87             64                500         \n",
    "     11,0651788711548           0,65           0,65           0,88             64                1000        \n",
    "     22,8105053901672           0,59           0,59           0,86             64                2000        \n",
    "     35,7798202037811           0,66           0,66           0,89             64                3000        \n",
    "     47,2166092395783           0,67           0,67           0,89             64                4000        \n",
    "     57,4432139396667           0,59           0,59           0,86             64                5000        \n",
    "     1,38666915893555            0,6            0,6           0,87            128                100         \n",
    "     7,64422869682312           0,59           0,59           0,86            128                500         \n",
    "     12,9416465759277           0,62           0,62           0,87            128                1000        \n",
    "     26,5535976886749           0,62           0,62           0,87            128                2000        \n",
    "     39,8996198177338           0,61           0,61           0,87            128                3000        \n",
    "     53,5977177619934            0,6            0,6           0,87            128                4000        \n",
    "     61,1100986003876           0,54           0,54           0,85            128                5000        \n",
    "     1,31718754768372           0,56           0,56           0,85            256                100         \n",
    "     6,53408026695251           0,61           0,61           0,87            256                500         \n",
    "      15,244170665741           0,68           0,68           0,89            256                1000        \n",
    "     25,2375843524933           0,71           0,71           0,9             256                2000        \n",
    "     39,6007649898529           0,62           0,62           0,87            256                3000        \n",
    "     51,4709479808807           0,58           0,58           0,86            256                4000        \n",
    "     72,2376120090485            0,6            0,6           0,87            256                5000        \n",
    "     1,66196537017822            0,6            0,6           0,87            512                100         \n",
    "     7,15856194496155           0,65           0,65           0,88            512                500         \n",
    "     13,2321417331696           0,64           0,64           0,88            512                1000        \n",
    "     28,2267260551453           0,59           0,59           0,86            512                2000        \n",
    "     41,2145173549652           0,63           0,63           0,88            512                3000        \n",
    "     52,7156758308411           0,61           0,61           0,87            512                4000        \n",
    "     68,2710967063904           0,61           0,61           0,87            512                5000        \n",
    "     1,75580477714539           0,49           0,49           0,83            1024               100         \n",
    "     8,71928930282593            0,6            0,6           0,87            1024               500         \n",
    "     16,2291495800018            0,6            0,6           0,87            1024               1000        \n",
    "     32,7664318084717           0,59           0,59           0,86            1024               2000        \n",
    "     51,9011363983154            0,5            0,5           0,83            1024               3000        \n",
    "     61,7052772045136           0,59           0,59           0,86            1024               4000        \n",
    "     66,8048763275147           0,57           0,57           0,86            1024               5000 \n",
    "\n",
    "![](https://github.com/axell-brendow/image-processing-work/blob/main/assets/table1.png?raw=true)\n",
    "\n",
    " Matriz de confusão gerada:\n",
    " \n",
    "![](https://github.com/axell-brendow/image-processing-work/blob/main/assets/image1.png?raw=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referências\n",
    "\n",
    "**Move and zoom a tkinter canvas with mouse**. stackoverflow, 2020. Disponível em: https://stackoverflow.com/questions/25787523/move-and-zoom-a-tkinter-canvas-with-mouse/48069295#48069295. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**Tkinter canvas zoom move pan**. stackoverflow, 2020. Disponível em: https://stackoverflow.com/questions/41656176/tkinter-canvas-zoom-move-pan/48137257#48137257. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**Textural Features for Image Classification**. ieeexplore, 2020. Disponível em: https://ieeexplore.ieee.org/document/4309314. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**How-can-i-convert-an-rgb-image-into-grayscale-in-python**. stackoverflow, 2020. Disponível em: https://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**Opencv-shape-descriptor-hu-moments-example**. pyimagesearch, 2020. Disponível em: https://www.pyimagesearch.com/2014/10/27/opencv-shape-descriptor-hu-moments-example/. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**Texture Recognition using Haralick Texture and Python**. gogul, 2020. Disponível em: https://gogul.dev/software/texture-recognition. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**Tensorflow Image Classification | Build Your Own Image Classifier In Tensorflow | Edureka**. youtube, 2020. Disponível em: https://www.youtube.com/watch?v=AACPaoDsd50&ab_channel=edureka%21. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**Treine sua primeira rede neural: classificação básica**. tensorflow, 2020. Disponível em: https://www.tensorflow.org/tutorials/keras/classification?hl=pt-br#fa%C3%A7a_predi%C3%A7%C3%B5es. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**Confusion Matrix for Your Multi-Class Machine Learning Model**. towardsdatascience, 2020. Disponível em: https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826. Acesso em: 20, Novembro de 2020.\n",
    "\n",
    "**Scikit-learn: How to obtain True Positive, True Negative, False Positive and False Negative**. stackoverflow, 2020. Disponível em: https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal. Acesso em: 20, Novembro de 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
